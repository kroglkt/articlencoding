{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder Implementation\n",
    "This is the notebook for the autoencoder we will use for automatic feature extraction. At the moment it is more of a test, than actual implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "max_features = 100000\n",
    "epochs = 15\n",
    "\n",
    "#Load some data. Will be tested on headlines\n",
    "with open('data/additional/preprocessed_data.json') as f:\n",
    "    data = pd.read_json(f)\n",
    "\n",
    "headers = list(data.Header)\n",
    "OG_X = data.Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: [3616, 3820, 50212, 64, 12, 999, 4092, 302, 369, 12, 71810, 1, 4] [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0  3616  3820 50212    64    12\n",
      "   999  4092   302   369    12 71810     1     4]\n",
      "Utilfreds passager: »Prøv selv en tur klokken 7.30 en hverdagsmorgen« - Svirdur.dk ---> utilfreds passager »prøv selv en tur klokken 7 30 en hverdagsmorgen« svirdur dk\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(OG_X))\n",
    "X_old = tokenizer.texts_to_sequences(OG_X)\n",
    "X = pad_sequences(X_old, maxlen=max_len)\n",
    "print(\"vectors:\", X_old[0], X[0])\n",
    "print(headers[0], \"--->\", tokenizer.sequences_to_texts(X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           5000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200, 150)          75600     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 200, 50)           35200     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 200, 150)          75600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               10200     \n",
      "=================================================================\n",
      "Total params: 5,204,150\n",
      "Trainable params: 5,204,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPooling1D, Dense\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "\n",
    "inp = Input(shape=(max_len,))\n",
    "\n",
    "encoder = Embedding(max_features, 50)(inp)\n",
    "encoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\n",
    "encoder = Bidirectional(LSTM(25, return_sequences=True, activity_regularizer=regularizers.l1(10e-5)))(encoder)\n",
    "\n",
    "decoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\n",
    "decoder = GlobalMaxPooling1D()(decoder)\n",
    "decoder = Dense(50, activation='relu')(decoder)\n",
    "decoder = Dense(max_len)(decoder)\n",
    "\n",
    "model = Model(inputs=inp, outputs=decoder)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4824/4824 [==============================] - 4310s 893ms/step - loss: 10089007.0000 - accuracy: 0.1606\n",
      "Epoch 2/15\n",
      "4824/4824 [==============================] - 4045s 838ms/step - loss: 8550543.0000 - accuracy: 0.2502\n",
      "Epoch 3/15\n",
      "4824/4824 [==============================] - 4007s 831ms/step - loss: 7761721.5000 - accuracy: 0.3642\n",
      "Epoch 4/15\n",
      "4824/4824 [==============================] - 4048s 839ms/step - loss: 6454305.0000 - accuracy: 0.5157\n",
      "Epoch 5/15\n",
      "4824/4824 [==============================] - 4088s 847ms/step - loss: 5507352.5000 - accuracy: 0.6054\n",
      "Epoch 6/15\n",
      "4824/4824 [==============================] - 4108s 852ms/step - loss: 4275972.5000 - accuracy: 0.6843\n",
      "Epoch 7/15\n",
      "4824/4824 [==============================] - 4088s 847ms/step - loss: 3427413.7500 - accuracy: 0.7579\n",
      "Epoch 8/15\n",
      "4824/4824 [==============================] - 4082s 846ms/step - loss: 2804465.2500 - accuracy: 0.8043\n",
      "Epoch 9/15\n",
      "4824/4824 [==============================] - 4112s 853ms/step - loss: 2229710.0000 - accuracy: 0.8382\n",
      "Epoch 10/15\n",
      "4824/4824 [==============================] - 4121s 854ms/step - loss: 1755700.8750 - accuracy: 0.8628\n",
      "Epoch 11/15\n",
      "4824/4824 [==============================] - 4120s 854ms/step - loss: 1519144.0000 - accuracy: 0.8730\n",
      "Epoch 12/15\n",
      "4824/4824 [==============================] - 4140s 858ms/step - loss: 1447572.6250 - accuracy: 0.8757\n",
      "Epoch 13/15\n",
      "4824/4824 [==============================] - 4190s 869ms/step - loss: 1316658.2500 - accuracy: 0.8874\n",
      "Epoch 14/15\n",
      "4824/4824 [==============================] - 4213s 873ms/step - loss: 1139343.6250 - accuracy: 0.9022\n",
      "Epoch 15/15\n",
      "4824/4824 [==============================] - 4198s 870ms/step - loss: 1069281.2500 - accuracy: 0.9063\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X, X, epochs=epochs, batch_size=64, verbose=1)\n",
    "#model.save_weights(f'models/model{epochs}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9647/9647 [==============================] - 1506s 156ms/step - loss: 1049805.2500 - accuracy: 0.9077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1049805.25, 0.907718300819397]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilfreds passager: »Prøv selv en tur klokken 7.30 en hverdagsmorgen« - Svirdur.dk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"svirdur svirdur svirdur svirdur er det i skal er dk er blev i bladet der for 2 efter hvad danmarks endnu sætter kina syv finde 23 fart væltet forgæves kur ansøgning mh370 tsi vanvid anholdt lad lussing tdc fc 1980'er chef 14\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = headers[0]\n",
    "print(st)\n",
    "st = tokenizer.texts_to_sequences([st])\n",
    "st = pad_sequences(st, maxlen=max_len)\n",
    "ny = model.predict(st)\n",
    "ny = np.rint(ny).astype(np.int64)\n",
    "tokenizer.sequences_to_texts(ny)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import hashing_trick, one_hot, text_to_word_sequence\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 3, 3, 5, 3, 3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Jeg en gård mig bygge vil'\n",
    "seq = text_to_word_sequence(text)\n",
    "vocab_size = len(seq)\n",
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'string 1',\n",
    "    'string 2',\n",
    "    'Niels er Niels',\n",
    "    'Niels er string',\n",
    "    'Niels går der'\n",
    "    'Der er en and'\n",
    "    'En and er en string'\n",
    "]\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(corpus)\n",
    "vocab_size = len(t.word_index)+1\n",
    "X = t.texts_to_sequences(corpus)\n",
    "X = pad_sequences(X, maxlen=8, padding='post')\n",
    "\n",
    "#Encode output X\n",
    "ylist = []\n",
    "for sequence in X:\n",
    "    encoded = keras.utils.to_categorical(sequence, num_classes=vocab_size)\n",
    "    ylist.append(encoded)\n",
    "y = np.array(ylist)\n",
    "y = y.reshape(X.shape[0], X.shape[1], vocab_size)\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = []\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import RepeatVector, TimeDistributed\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "model = define_model(vocab_size, vocab_size, 8, 8, 100)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.3422\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3246\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3031\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.2767\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.2441\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.2039\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1540\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 2.0926\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.0174\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc42753848>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sequence(model, t, X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 11)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X[0])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
