{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for extracting features for authorship attribution.\n",
    "In this notebook all authorship attribution features will be collected. They will be saved after extraction. Make sure, you define each feature extraction in a function, so it easily can be repurposed.\n",
    "\n",
    "Author: lkt259@alumni.ku.dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence length\n",
    "Nice feature, very complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"This list has overlapping features with content features. For example, word n-grams will capture the content of the text along with stylometric tendencies. Content features consist of word frequencies, word and character n-grams, hapax legomena etc. This overlap is not of concern, however, as Sari et al. \\cite{Sari2018} show, using content features is beneficial when performing authorship attribution of news articles because journalists often have certain topics they prefer writing about. They argue that using only stylometric features is beneficial when attributing authors to texts of the same topic or genre, e.g. law text or movie reviews.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 15, 13, 11, 24, 26]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence lengths\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_len_chars': 107.33333333333333,\n",
       " 'std_len_chars': 48.65410796862093,\n",
       " 'median_len_chars': 95.0,\n",
       " 'mean_len_words': 16.166666666666668,\n",
       " 'std_len_words': 6.618576550554926,\n",
       " 'median_len_words': 14.0}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sentences(text):\n",
    "    '''Returns an array with text split into sentences'''\n",
    "    return np.array(re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text), dtype=str)\n",
    "\n",
    "def split_words(text):\n",
    "    '''Returns an array with text split into words'''\n",
    "    #The best solution, really...\n",
    "    return np.array(text.split(), dtype=str)\n",
    "\n",
    "def get_sentence_lengths(text):\n",
    "    '''Returns dictionary with sentence lengh in chars and words'''\n",
    "    split_text = split_sentences(text)\n",
    "    num_chars = np.array([len(x) for x in split_text], dtype=int)\n",
    "    num_words = [split_words(x).size for x in split_sentences(string)]\n",
    "    return {'chars' : num_chars, 'words' : num_words}\n",
    "\n",
    "def get_sentence_length_stats(text):\n",
    "    '''Returns dictionary with mean, std and median lengths in both chars and words'''\n",
    "    sentence_lengths = get_sentence_lengths(text)\n",
    "    output = {'avg_len_chars' : np.mean(sentence_lengths['chars']),\n",
    "              'std_len_chars' : np.std(sentence_lengths['chars']),\n",
    "              'med_len_chars' : np.median(sentence_lengths['chars']),\n",
    "              \n",
    "              'avg_len_words' : np.mean(sentence_lengths['words']),\n",
    "              'std_len_words' : np.std(sentence_lengths['words']),\n",
    "              'med_len_words' : np.median(sentence_lengths['words'])\n",
    "             }\n",
    "    return output\n",
    "\n",
    "print(\"Test sentence lengths\")\n",
    "get_sentence_length_stats(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word length\n",
    "The count of words of the entire text.\n",
    "Also extremely complex feature, cool shit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test word lengths\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.701030927835052, 2.893878888215957, 5.0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_char_lengths(text):\n",
    "    split_text = split_words(text)\n",
    "    return np.array([len(x) for x in split_text], dtype=int)\n",
    "\n",
    "def get_word_length_char_stats(text):\n",
    "    word_lengths = get_word_lengths(text)\n",
    "    return np.mean(word_lengths), np.std(word_lengths), np.median(word_lengths)\n",
    "\n",
    "print(\"Test word lengths\")\n",
    "get_word_length_stats(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-aa785adca3fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "split_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.'.isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
