{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder Implementation\n",
    "This is the notebook for the autoencoder we will use for automatic feature extraction. At the moment it is more of a test, than actual implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "max_features = 100000\n",
    "epochs = 4\n",
    "\n",
    "#Load some data. Will be tested on headlines\n",
    "with open('data/additional/preprocessed_data.json') as f:\n",
    "    data = pd.read_json(f)\n",
    "\n",
    "headers = list(data.Header)\n",
    "OG_X = data.Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: [3505, 20096, 57837, 66, 14, 1030, 3695, 88602, 14, 88603, 1, 8] [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0  3505 20096 57837    66    14  1030  3695 88602    14 88603\n",
      "     1     8]\n",
      "Utilfreds passager: »Prøv selv en tur klokken 7.30 en hverdagsmorgen« - Svirdur.dk ---> utilfreds passager: »prøv selv en tur klokken 7.30 en hverdagsmorgen« - svirdur.dk\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=\"\", num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(OG_X))\n",
    "X_old = tokenizer.texts_to_sequences(OG_X)\n",
    "X = pad_sequences(X_old, maxlen=max_len)\n",
    "print(\"vectors:\", X_old[0], X[0])\n",
    "print(headers[0], \"--->\", tokenizer.sequences_to_texts(X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 50)            5000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 150)           75600     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 50)            35200     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 50, 150)           75600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "=================================================================\n",
      "Total params: 5,196,500\n",
      "Trainable params: 5,196,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPooling1D, Dense\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "\n",
    "inp = Input(shape=(max_len,))\n",
    "\n",
    "encoder = Embedding(max_features, 50)(inp)\n",
    "encoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\n",
    "encoder = Bidirectional(LSTM(25, return_sequences=True, activity_regularizer=regularizers.l1(10e-5)))(encoder)\n",
    "\n",
    "decoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\n",
    "decoder = GlobalMaxPooling1D()(decoder)\n",
    "decoder = Dense(50, activation='relu')(decoder)\n",
    "decoder = Dense(max_len)(decoder)\n",
    "\n",
    "model = Model(inputs=inp, outputs=decoder)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4824/4824 [==============================] - 833s 173ms/step - loss: 41240164.0000 - accuracy: 0.1618\n",
      "Epoch 2/4\n",
      "4824/4824 [==============================] - 897s 186ms/step - loss: 34247744.0000 - accuracy: 0.2585\n",
      "Epoch 3/4\n",
      "4824/4824 [==============================] - 904s 187ms/step - loss: 30900030.0000 - accuracy: 0.3549\n",
      "Epoch 4/4\n",
      "4824/4824 [==============================] - 807s 167ms/step - loss: 26595800.0000 - accuracy: 0.4929\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, X, epochs=epochs, batch_size=64, verbose=1)\n",
    "model.save_weights(f'models/model{epochs}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9647/9647 [==============================] - 286s 30ms/step - loss: 23527452.0000 - accuracy: 0.5764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23527452.0, 0.576382577419281]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilfreds passager: »Prøv selv en tur klokken 7.30 en hverdagsmorgen« - Svirdur.dk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'er er på til på - | | i om på kroner går fra verdens have øst mellem næste hvis hele læs historien hus fortæller strand qvortrup larmer 81-årig kinderne sareen: klaver amager-metro invest'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = headers[0]\n",
    "print(st)\n",
    "st = tokenizer.texts_to_sequences([st])\n",
    "st = pad_sequences(st, maxlen=max_len)\n",
    "ny = model.predict(st)\n",
    "ny = np.rint(ny).astype(np.int64)\n",
    "tokenizer.sequences_to_texts(ny)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     8,     8,     8,    66,    14,  1030,  3695,\n",
       "        88602,    14, 88603,     1,     8]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st[0][38:41] = 8\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svirdur.dk svirdur.dk svirdur.dk selv en tur klokken 7.30 en hverdagsmorgen« - svirdur.dk'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(st)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utilfreds passager: »prøv selv en tur klokken 7.30 en hverdagsmorgen« - svirdur.dk'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(st)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,   409,   852,  2156,  4306,  9056, 13246, 24793,\n",
       "        28297, 26146, 58938,   -36, 10739]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny[0][0:38] = 0\n",
    "ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hus fortæller strand qvortrup larmer 81-årig kinderne sareen: klaver amager-metro invest'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(ny)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
